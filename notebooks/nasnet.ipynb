{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Image directories\n",
    "dataset_dir = '../dataset/images'\n",
    "train_dir = '../dataset/train'\n",
    "validation_dir = '../dataset/val'\n",
    "test_dir = '../dataset/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of breeds: 120\n"
     ]
    }
   ],
   "source": [
    "# Function to delete and recreate directories\n",
    "def reset_directory(directory):\n",
    "    if os.path.exists(directory):\n",
    "        shutil.rmtree(directory)\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "# Reset train, validation, and test directories\n",
    "reset_directory(train_dir)\n",
    "reset_directory(val_dir)\n",
    "reset_directory(test_dir)\n",
    "\n",
    "# Get all subdirectories (each representing a dog breed)\n",
    "breed_dirs = [d for d in os.listdir(dataset_dir) if os.path.isdir(os.path.join(dataset_dir, d))]\n",
    "\n",
    "print(f'Number of breeds: {len(breed_dirs)}')\n",
    "\n",
    "# Iterate through each breed directory\n",
    "for breed in breed_dirs:\n",
    "    breed_path = os.path.join(dataset_dir, breed)\n",
    "    images = [os.path.join(breed_path, img) for img in os.listdir(breed_path) if img.endswith(('jpg', 'jpeg', 'png'))]\n",
    "\n",
    "    # Split the images into train, validation, and test sets\n",
    "    train_images, temp_images = train_test_split(images, test_size=0.3, random_state=42)\n",
    "    val_images, test_images = train_test_split(temp_images, test_size=0.5, random_state=42)\n",
    "\n",
    "    # Create breed directories in train, validation, and test directories\n",
    "    os.makedirs(os.path.join(train_dir, breed), exist_ok=True)\n",
    "    os.makedirs(os.path.join(validation_dir, breed), exist_ok=True)\n",
    "    os.makedirs(os.path.join(test_dir, breed), exist_ok=True)\n",
    "\n",
    "    # Function to copy images to respective directories\n",
    "    def copy_images(image_list, target_dir):\n",
    "        for image_path in image_list:\n",
    "            shutil.copy(image_path, os.path.join(target_dir, breed))\n",
    "\n",
    "    # Copy images to train, validation, and test directories\n",
    "    copy_images(train_images, train_dir)\n",
    "    copy_images(val_images, validation_dir)\n",
    "    copy_images(test_images, test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generator functions\n",
    "def create_datagen(preprocessing_function =\"\"):\n",
    "    return ImageDataGenerator(\n",
    "        preprocessing_function=preprocessing_function,\n",
    "        rescale=1./255,  # Normalize pixel values\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "    )\n",
    "def create_generator(datagen, directory, shuffle):\n",
    "    return datagen.flow_from_directory(\n",
    "        directory,\n",
    "        target_size=(224,224),\n",
    "        batch_size=16,\n",
    "        class_mode='categorical',\n",
    "        shuffle=shuffle,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data generators\n",
    "datagen_nasnet = create_datagen(tf.keras.applications.vgg16.preprocess_input)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator_nasnet = create_generator(datagen_nasnet, train_dir, True)\n",
    "val_generator = create_generator(val_datagen, validation_dir, True)\n",
    "test_generator = create_generator(test_datagen, test_dir, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Building\n",
    "nasnet_model = tf.keras.applications.NASNetLarge(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "x = nasnet_model.output\n",
    "# Freeze base model layers\n",
    "nasnet_model.trainable = False\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
    "x_preds = tf.keras.layers.Dense(120, activation='softmax')(x)\n",
    "nasnet_model = tf.keras.Model(inputs=nasnet_model.input, outputs=x_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasnet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasnet_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training\n",
    "history = nasnet_model.fit(train_generator_nasnet, validation_data=val_generator, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test data\n",
    "test_loss, test_acc = nasnet_model.evaluate(test_generator, steps=test_generator.classes.size)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_acc}\")\n",
    "\n",
    "# Reset the test generator\n",
    "test_generator.reset()\n",
    "\n",
    "# Get the predictions\n",
    "predictions = nasnet_model.predict(test_generator, steps=test_generator.classes.size)\n",
    "\n",
    "# Get true labels\n",
    "y_true = test_generator.classes\n",
    "\n",
    "# Convert predicted probabilities to class labels\n",
    "threshold = 0.5\n",
    "y_pred = (predictions > threshold).astype(int).flatten()\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true, y_pred, zero_division=1))\n",
    "\n",
    "# Print confusion matrix with labels\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "conf_matrix_flipped = conf_matrix[[1, 0], :]  # Flip the rows\n",
    "conf_matrix_flipped = conf_matrix_flipped[:, [1, 0]]  # Flip the columns\n",
    "conf_matrix_df = pd.DataFrame(conf_matrix_flipped, index=[\"True BMR\", \"True Non-BMR\"], columns=[\"Predicted BMR\", \"Predicted Non-BMR\"])\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_df)\n",
    "\n",
    "# Set the size of the plot\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Set the font scale\n",
    "sns.set(font_scale=2)\n",
    "\n",
    "sns.heatmap(conf_matrix_df, annot=True, fmt='d', cmap='Blues', cbar_kws={'label': 'Count'})\n",
    "\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion Matrix')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Calculate accuracy from confusion matrix\n",
    "accuracy = np.trace(conf_matrix) / np.sum(conf_matrix)\n",
    "print(f\"Calculated Accuracy from Confusion Matrix: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation accuracy\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy', marker='o')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Accuracy', marker='o')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(history.history['loss'], label='Train Loss', marker='o')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss', marker='o')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
